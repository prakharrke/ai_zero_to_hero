{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3a137b0c-500b-4079-bcb2-1f8b0d8d35fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/pdixit/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "803c95c7-e406-4482-9d76-6d38639a05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ed63cbde-2991-444c-9b98-97b8a4590107",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"Book1.txt\", encoding=\"utf8\") as f:\n",
    "    book = f.read()\n",
    "    book_pages = re.sub(\"Page.*?Rowling\", \"\", book, flags=re.DOTALL)\n",
    "    book_chapters = re.sub(\"(?:\\\\n){5,}[A-Z- \\\\n]+ (?:\\\\n){2,}\", \"\", book_pages)\n",
    "    book_line_breaks = re.sub(\"\\\\n\", \"\", book_chapters)\n",
    "    sentence_split = sent_tokenize(book_chapters)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d352b6ee-60c9-4373-9c9e-68b8f58a7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sentences = [sentence.lower() for sentence in sentence_split]\n",
    "\n",
    "processed_sentences = [sent.lower() for sent in sentence_split if len(sent.strip()) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "fe296d6f-64dd-44bd-9dda-d198410f5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "vocab = string.ascii_lowercase + string.digits + string.punctuation + '“' + '”' + '’' + '—' + '‘' + \" \" + '•' \n",
    "stoi = {char: idx for idx, char in enumerate(vocab)}\n",
    "itos = {idx: char for idx, char in enumerate(vocab)}\n",
    "stoi['<S>'] = len(stoi)\n",
    "itos[len(itos)] = '<S>'\n",
    "vocab_size = len(stoi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "7828e3ac-c9f0-4309-b92e-9b7eac7e6bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle sentences\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(processed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "99374c3a-7b7e-4c6e-b861-d9c82e0eee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([350021, 100]), Y shape: torch.Size([350021])\n",
      "X shape: torch.Size([43670, 100]), Y shape: torch.Size([43670])\n",
      "X shape: torch.Size([42532, 100]), Y shape: torch.Size([42532])\n"
     ]
    }
   ],
   "source": [
    "block_size = 100  # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(sentences):  \n",
    "    X, Y = [], []\n",
    "    for sentence in sentences:\n",
    "        context = [stoi['<S>']] * block_size  # Start with <S> token\n",
    "        for ch in sentence + ' ':\n",
    "            if ch not in stoi:  # Check if the character is in the vocabulary\n",
    "                continue\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            \n",
    "            # Slide the window: crop context to the last `block_size` characters and append the current character\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "    return X, Y\n",
    "\n",
    "# Split the data into train, dev, and test sets\n",
    "n1 = int(0.8 * len(processed_sentences))  # 80% for training\n",
    "n2 = int(0.9 * len(processed_sentences))  # 10% for dev\n",
    "Xtr, Ytr = build_dataset(processed_sentences[:n1])  # Training data\n",
    "Xdev, Ydev = build_dataset(processed_sentences[n1:n2])  # Validation data\n",
    "Xte, Yte = build_dataset(processed_sentences[n2:])  # Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "4a921fe4-0923-49f9-b1ee-db5fade8b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out), device=device) / fan_in**0.5 # note: kaiming init\n",
    "    self.bias = torch.zeros(fan_out, device=device) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    \n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # Parameters (trainable via backprop)\n",
    "    self.gamma = torch.ones(dim, device=device).view(1, -1, 1)  # Shape [1, C, 1]\n",
    "    self.beta = torch.zeros(dim, device=device).view(1, -1, 1)  # Shape [1, C, 1]\n",
    "    # Buffers (updated via momentum)\n",
    "    self.running_mean = torch.zeros(dim, device=device)  # Shape [C]\n",
    "    self.running_var = torch.ones(dim, device=device)    # Shape [C]\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    if self.training:\n",
    "      # Compute mean and variance across batch and sequence length (dim=(0,2))\n",
    "      xmean = x.mean(dim=(0, 2), keepdim=True)  # Shape [1, C, 1]\n",
    "      xvar = x.var(dim=(0, 2), keepdim=True)    # Shape [1, C, 1]\n",
    "    else:\n",
    "      # Use running statistics for inference\n",
    "      xmean = self.running_mean.view(1, -1, 1)  # Shape [1, C, 1]\n",
    "      xvar = self.running_var.view(1, -1, 1)    # Shape [1, C, 1]\n",
    "    \n",
    "    # Normalize input\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps)  # Normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta         # Scale and shift\n",
    "\n",
    "    # Update running statistics during training\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean.squeeze()\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar.squeeze()\n",
    "    \n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    # Return trainable parameters\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Embedding:\n",
    "  \n",
    "  def __init__(self, num_embeddings, embedding_dim):\n",
    "    self.weight = torch.randn((num_embeddings, embedding_dim), device=device)\n",
    "    \n",
    "  def __call__(self, IX):\n",
    "    self.out = self.weight[IX].transpose(1, 2)\n",
    "    \n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class FlattenConsecutive:\n",
    "  \n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    B, T, C = x.shape\n",
    "    x = x.view(B, T//self.n, C*self.n)\n",
    "    if x.shape[1] == 1:\n",
    "      x = x.squeeze(1)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        self.out = x.view(x.shape[0], -1)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Sequential:\n",
    "  \n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    # get parameters of all layers and stretch them out into one list\n",
    "    return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "# --------------------------------------------\n",
    "class Conv1d:\n",
    "    def __init__(self, sequence_length, in_channels, out_channels, kernel=2, stride=1, dilation=1):\n",
    "        self. sequence_length = sequence_length\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.filters = torch.randn((out_channels, in_channels, kernel), device=device) * ((2 / (in_channels * kernel)) ** 0.5)\n",
    "        self.bias = torch.randn(out_channels, device=device) * 0\n",
    "        self.effective_kernel = ((self.kernel - 1) * self.dilation) + 1\n",
    "        self.Lout = ((self.sequence_length - self.effective_kernel) // self.stride) + 1\n",
    "    def __call__(self, x):\n",
    "        # Compute effective kernel size based on dilation \n",
    "        # effective_kernel = ((self.kernel - 1) * self.dilation) + 1\n",
    "        \n",
    "        N, C, L = x.shape\n",
    "        assert self.effective_kernel <= L\n",
    "            \n",
    "        # create the sliding windows of the input \n",
    "        x_unfolded = x.unfold(2, self.effective_kernel, self.stride)\n",
    "\n",
    "        # Extract dilated inputs from x_unfolded which used effective_kernel. The shape of the unfolded vector is [N, C, L, effective_k] \n",
    "        # where L is the length of the sequence depending on the effective kernel. From the dimension of effective_kernel, we clip every 'dilated' index\n",
    "        # If effective_kernel is 3 and dilation is 2, [1, 2, 3] will result in [1, 3]. [1,3] has length of 2, which is equal to actual kernel value\n",
    "        x_unfolded = x_unfolded[:, :, :, ::self.dilation]\n",
    "\n",
    "        # The dilation also changes the sequence length, since effective kernel value changes with dilation > 1. \n",
    "        # Compute Lout based on effective_kernel\n",
    "        \n",
    "        # Lout = ((self.sequence_length - self.effective_kernel) // self.stride) + 1\n",
    "        \n",
    "        # Before cross correlation, we need to broadcast the filters and the input correctly\n",
    "        x_unfolded = x_unfolded.view(N, 1, C, self.Lout, self.kernel)\n",
    "        filters = self.filters.view(1, self.out_channels, self.in_channels, 1, self.kernel)\n",
    "\n",
    "        # Perform element wise multiplication\n",
    "        self.out = torch.mul(x_unfolded, filters).sum((2, 4)) + self.bias.view(1, self.out_channels, 1)\n",
    "        return self.out        \n",
    "    \n",
    "    def parameters(self): \n",
    "        return [self.filters] + [self.bias]\n",
    "\n",
    "class ReLu: \n",
    "    def __call__(self, x):\n",
    "        self.out = torch.relu(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "        \n",
    "class Transpose:\n",
    "    def __call__(self, x):\n",
    "        self.out = x.transpose(1, 2)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Residual: \n",
    "    def __init__(self, layers):\n",
    "        self.projection_needed = False\n",
    "        self.layers = layers\n",
    "        \n",
    "        \n",
    "        # Input of the in layer config\n",
    "        in_layer = layers[0]\n",
    "        out_layer = layers[-1]\n",
    "\n",
    "        self.in_channels = in_layer.in_channels\n",
    "        self.in_sequence_length = in_layer.sequence_length\n",
    "\n",
    "        self.out_channels = out_layer.out_channels\n",
    "        self.out_sequence_length = out_layer.Lout\n",
    "\n",
    "        if self.in_channels != self.out_channels: # Assuming for now, this will always be the case\n",
    "            self.projection_needed = True\n",
    "            self.linear_projection_conv = Conv1d(sequence_length=self.in_sequence_length, out_channels=self.out_channels, in_channels=self.in_channels, kernel=1)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        self.input = x\n",
    "        for layer in self.layers: \n",
    "            x = layer(x)\n",
    "        # Perform residual operation\n",
    "        if self.projection_needed:\n",
    "            linear_projection = self.linear_projection_conv(self.input)\n",
    "            \n",
    "        # Pad the output since the Lout != Lin\n",
    "        sequence_length_diff = self.in_sequence_length - self.out_sequence_length\n",
    "        x = F.pad(x, (sequence_length_diff // 2, sequence_length_diff - sequence_length_diff // 2))\n",
    "        \n",
    "        self.out = x + linear_projection if self.projection_needed else x + self.input\n",
    "        \n",
    "        return self.out\n",
    "        \n",
    "    def parameters(self):\n",
    "        # Collect parameters from all layers and the projection (if used)\n",
    "        params = [p for layer in self.layers for p in layer.parameters()]\n",
    "        if self.projection_needed:\n",
    "            params += self.linear_projection_conv.parameters()\n",
    "        return params\n",
    "\n",
    "class ElmanRNN:\n",
    "    def __init__(self, input_channels, hidden_channels): # Bias would be present. Tanh non linearity will be applied. \n",
    "        self.wxh = torch.randn((input_channels, hidden_channels), device=device) * (5/3 / (input_channels) ** 0.5)\n",
    "        self.bxh = torch.randn((1, hidden_channels), device=device) * 0.001\n",
    "        \n",
    "        self.whh = torch.randn((hidden_channels, hidden_channels), device=device) * (5/3 / (hidden_channels) ** 0.5)\n",
    "        self.bhh = torch.randn((1, hidden_channels), device=device) * 0.001\n",
    "        \n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.input_channels = input_channels\n",
    "\n",
    "    def __call__(self, x):\n",
    "        N, C, L = x.shape\n",
    "\n",
    "        # Iterate over the entire sequence length and generate logits. The shape of the output logits will be [N, Hout, L]\n",
    "        logits = torch.zeros((N, self.hidden_channels, L), device=device)\n",
    "        H = torch.zeros((N, self.hidden_channels), device=device)\n",
    "        for i in range(L):\n",
    "            xi = x[:, :, i]\n",
    "            xih = (xi @ self.wxh) + self.bxh\n",
    "            hh = (H @ self.whh) + self.bhh\n",
    "            ht = torch.tanh(xih + hh)\n",
    "            \n",
    "            H = ht \n",
    "            logits[:, :, i] = ht\n",
    "            self.out = logits\n",
    "            \n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.wxh] + [self.whh] + [self.bxh] + [self.bhh]\n",
    "\n",
    "class LSTM:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Define gate weights \n",
    "        # Input Gate weights\n",
    "        self. wii = torch.randn((input_size, hidden_size))\n",
    "        self.whi = torch.randn((hidden_size, hidden_size))\n",
    "        self.bii = torch.randn(hidden_size)\n",
    "        \n",
    "        # Forget Gate weights \n",
    "        self.wif = torch.randn((input_size, hidden_size))\n",
    "        self.whf = torch.randn((hidden_size, hidden_size))\n",
    "        self.bif = torch.randn(hidden_size)\n",
    "\n",
    "        # Cell candidiate weights \n",
    "        self.wig = torch.randn((input_size, hidden_size))\n",
    "        self.whg = torch.randn((hidden_size, hidden_size))\n",
    "        self.big = torch.randn(hidden_size)\n",
    "        # Output gate weights \n",
    "        self.wio = torch.randn((input_size, hidden_size))\n",
    "        self.who = torch.randn((hidden_size, hidden_size))\n",
    "        self.bio = torch.randn(hidden_size)\n",
    "\n",
    "    def __call__(self, x, H=None, C=None):\n",
    "        # Shape of x will be [N, C, L]. N = batch size, C = input channel size, L = input sequence length \n",
    "        N, I, L = x.shape \n",
    "        if H == None:\n",
    "            H = torch.zeros((N, self.hidden_size))\n",
    "        if C == None: \n",
    "            C = torch.zeros((N, self.hidden_size))\n",
    "        logits = torch.zeros((N, self.hidden_size, L))\n",
    "        for i in range(x.shape[2]):\n",
    "            xi = x[:, :, i]\n",
    "            # Compute gate vectors \n",
    "            it = torch.sigmoid((xi @ self.wii) + (H @ self.whi) + self.bii)\n",
    "            ft = torch.sigmoid((xi @ self.wif) + (H @ self.whf) + self.bif)\n",
    "            gt = torch.tanh((xi @ self.wig) + (H @ self.whg) + self.big)\n",
    "            ot = torch.sigmoid((xi @ self.wio) + (H @ self.who) + self.bio)\n",
    "            ct = (ft * C) + (it * gt)\n",
    "            C = ct\n",
    "            ht = ot * torch.tanh(ct)\n",
    "            H = ht\n",
    "            logits[:, :, i] = ht\n",
    "        self.out = logits\n",
    "        self.C = C\n",
    "        return self.out, self.C\n",
    "    def parameters(self):\n",
    "        return [self.wii, self.whi, self.bii] + [self.wif, self.whf, self.bif] + [self.wig, self.whg, self.big] + [self.wio, self.who, self.bio]\n",
    "\n",
    "class LayeredLSTM:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "\n",
    "    def __call__(self, x, h=None, c=None):\n",
    "        N, I, L = x.shape  # N=batch size, I=input channels, L=sequence length\n",
    "\n",
    "        if h is None:\n",
    "            h = [torch.zeros((N, layer.hidden_size)) for layer in self.layers]\n",
    "        if c is None:\n",
    "            c = [torch.zeros((N, layer.hidden_size)) for layer in self.layers]\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x, cell_state = layer(x, h[i], c[i])\n",
    "            h[i] = x[:, :, -1]\n",
    "            c[i] = cell_state\n",
    "        \n",
    "        return x\n",
    "    def parameters(self): \n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2c0b3ed8-50dd-45a3-bbc4-f61bc6c1e04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: 892300\n"
     ]
    }
   ],
   "source": [
    "n_embeddings = 24\n",
    "h_channels = 100\n",
    "h2_channels = 100\n",
    "# h3_channels = 500\n",
    "# h4_channels = 100\n",
    "# h4_channels = 100\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embeddings),\n",
    "    LayeredLSTM([\n",
    "        LSTM(n_embeddings, h_channels),\n",
    "        LSTM(h_channels, h2_channels),\n",
    "    ]),\n",
    "    \n",
    "    Flatten(), Linear(h2_channels * block_size, vocab_size)\n",
    "])\n",
    "# parameters = [p for layer in layers for p in layer.parameters()]\n",
    "print(f\"parameters: {sum(p.nelement() for p in model.parameters())}\")\n",
    "\n",
    "for p in model.parameters():\n",
    "        p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a77b3027-4286-428d-86fc-4a8ce4a5e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "eeb6cf04-4a25-401c-9900-2642134e79e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 100000: 4.3848\n",
      "   1000/ 100000: 4.3948\n",
      "   2000/ 100000: 4.4629\n",
      "   3000/ 100000: 4.4761\n",
      "   4000/ 100000: 4.4475\n",
      "   5000/ 100000: 4.4450\n",
      "   6000/ 100000: 4.3374\n",
      "   7000/ 100000: 4.2687\n",
      "   8000/ 100000: 4.2818\n",
      "   9000/ 100000: 4.3929\n",
      "  10000/ 100000: 4.3480\n",
      "  11000/ 100000: 4.4516\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[324], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m Xb, Yb \u001b[38;5;241m=\u001b[39m Xtr[ix], Ytr[ix] \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Forward pass \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, Yb)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# backward \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[314], line 112\u001b[0m, in \u001b[0;36mSequential.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    111\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 112\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    114\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\n",
      "Cell \u001b[0;32mIn[314], line 320\u001b[0m, in \u001b[0;36mLayeredLSTM.__call__\u001b[0;34m(self, x, h, c)\u001b[0m\n\u001b[1;32m    317\u001b[0m     c \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mzeros((N, layer\u001b[38;5;241m.\u001b[39mhidden_size)) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers]\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m--> 320\u001b[0m     x, cell_state \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     h[i] \u001b[38;5;241m=\u001b[39m x[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    322\u001b[0m     c[i] \u001b[38;5;241m=\u001b[39m cell_state\n",
      "Cell \u001b[0;32mIn[314], line 293\u001b[0m, in \u001b[0;36mLSTM.__call__\u001b[0;34m(self, x, H, C)\u001b[0m\n\u001b[1;32m    291\u001b[0m it \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid((xi \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwii) \u001b[38;5;241m+\u001b[39m (H \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhi) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbii)\n\u001b[1;32m    292\u001b[0m ft \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid((xi \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwif) \u001b[38;5;241m+\u001b[39m (H \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhf) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbif)\n\u001b[0;32m--> 293\u001b[0m gt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m ot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid((xi \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwio) \u001b[38;5;241m+\u001b[39m (H \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwho) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbio)\n\u001b[1;32m    295\u001b[0m ct \u001b[38;5;241m=\u001b[39m (ft \u001b[38;5;241m*\u001b[39m C) \u001b[38;5;241m+\u001b[39m (it \u001b[38;5;241m*\u001b[39m gt)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "start_time = time.time_ns()\n",
    "max_steps = 100000\n",
    "for i in range(max_steps): \n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] \n",
    "    \n",
    "    # Forward pass \n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb)\n",
    "    \n",
    "    # backward \n",
    "    for p in model.parameters():\n",
    "        p.grad = None\n",
    "    loss.backward() \n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "    \n",
    "    # Update the parameters \n",
    "    e = 0.01  if i < 20_000 else 0.005\n",
    "    for p in model.parameters():\n",
    "        p.data += -e * p.grad\n",
    "    \n",
    "    if i % 1000 == 0: # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "end_time = time.time_ns() \n",
    "print(f\"Total time: {(end_time - start_time) / 1_000_000_000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d1d7832c-b227-492c-8ddb-273c503dc947",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  \n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be3dca-4df6-48c1-a3dd-bd4a6dfe624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.training = False\n",
    "    \n",
    "# split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "94136286-da35-45f5-b5fd-52bcb3860d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(num_samples=2, max_length=100, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Samples sentences from the model.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_samples: Number of sentences to generate.\n",
    "    - max_length: Maximum length of each generated sentence.\n",
    "    - temperature: Sampling temperature to control randomness.\n",
    "    \n",
    "    Returns:\n",
    "    - res: List of generated sentences.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for _ in range(num_samples):\n",
    "        out = []\n",
    "        context = [stoi['<S>']] * block_size  # Initialize with all `<S>` tokens\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through the neural network\n",
    "            logits = model(torch.tensor([context], dtype=torch.long))  # Shape: (1, block_size)\n",
    "            \n",
    "            # If Flatten is used, logits will be (1 * block_size, vocab_size), so adjust:\n",
    "            logits = logits[-1, :]  # Take the logits for the last character\n",
    "            \n",
    "            # Apply temperature scaling\n",
    "            logits = logits / temperature\n",
    "            probs = F.softmax(logits, dim=0)\n",
    "            \n",
    "            # Sample from the probability distribution\n",
    "            ix = torch.multinomial(probs, num_samples=1).item()\n",
    "            \n",
    "            # Shift the context window and track the samples\n",
    "            context = context[1:] + [ix]\n",
    "            out.append(ix)\n",
    "            \n",
    "            # If the end token `<E>` or `.` is sampled, stop generation\n",
    "            if ix == stoi.get('.'):\n",
    "                break\n",
    "        \n",
    "        # Decode and append the generated sentence\n",
    "        res.append(''.join(itos[i] for i in out))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4b62ab27-605b-48b2-ad24-6d4fdd6f984a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marrys ane a aace said sy uta bedd leser acringitt as hoic o wpy ofwitar satred frip, ald sssape” do',\n",
       " '““r thee’sy cous aid seder, sued dranpenazbscaryybatn ae clute t oguta toen .']"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_from_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "55ad12f8-50f0-4376-9322-b37b927338c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = torch.tensor(lossi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d03a41a2-c5b0-47db-a1ec-04c5ae9bc30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12f44ac30>]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi.view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ff5d3b6d-f439-407a-937b-e1479e639ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S>his stomach twisted as he imagi'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([itos[c] for c in Xdev[96].tolist()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "98be3f08-12c7-435e-8500-0d7a77f64329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/84/r3s7dwr93cs3k0kzl447b_8c0000gp/T/ipykernel_82803/1197392954.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  probs = F.softmax(model(torch.tensor(context)), dim=1)\n"
     ]
    }
   ],
   "source": [
    "context = [stoi['<S>']] * block_size\n",
    "context = torch.tensor(context).view(1, -1)\n",
    "probs = F.softmax(model(torch.tensor(context)), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "2dfc9294-4310-4f60-951c-47171e4c9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = torch.multinomial(probs, num_samples=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c6f479cd-facf-42a8-82fe-c96fea689e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "1f04d106-9ac5-4ed5-aba1-c8aa25a59eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(model, stoi, itos, block_size, max_length=200, temperature=1.0, seed=\"<S>\"):\n",
    "    \"\"\"\n",
    "    Generates a sequence of characters from the trained model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained PyTorch model\n",
    "    - stoi: Dictionary mapping characters to indices\n",
    "    - itos: Dictionary mapping indices to characters\n",
    "    - block_size: Context size (length of input sequence to model)\n",
    "    - max_length: Maximum length of the generated sequence\n",
    "    - temperature: Softmax temperature for controlling randomness in sampling\n",
    "    - seed: Initial context to start generation\n",
    "    \n",
    "    Returns:\n",
    "    - generated_text: The generated sequence as a string\n",
    "    \"\"\"\n",
    "    # Start with the seed sequence\n",
    "    # context = [stoi[ch] for ch in seed if ch in stoi]  # Convert seed to indices\n",
    "    context = [stoi['<S>']] * (block_size)\n",
    "    print(context)\n",
    "    generated_indices = []\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        # Prepare input tensor\n",
    "        x = torch.tensor([context], dtype=torch.long)  # Shape: (1, block_size)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        logits = model(x)  # Shape: (1 * block_size, vocab_size)\n",
    "        logits = logits[-1, :]  # Take the logits for the last character in the sequence\n",
    "        \n",
    "        # Adjust for temperature\n",
    "        logits = logits / temperature\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Sample from the probability distribution\n",
    "        idx = torch.multinomial(probs, num_samples=1).item()\n",
    "        \n",
    "        # Add the predicted character to the generated output\n",
    "        generated_indices.append(idx)\n",
    "        context = context[1:] + [idx]  # Slide the context window\n",
    "        \n",
    "        # Stop if the end token `<E>` is generated\n",
    "        if itos[idx] == \".\":\n",
    "            break\n",
    "    \n",
    "    # Convert indices back to characters\n",
    "    generated_text = ''.join([itos[idx] for idx in generated_indices if itos[idx] not in {\"<S>\", \"<E>\"}])\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7731f3c4-024f-4bff-9497-6387b3fad118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75]\n",
      "Generated text: the carling iand s” ped testhey.\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"<S>\"  # Start token for generation\n",
    "generated_text = sample_from_model(model, stoi, itos, block_size=100, max_length=200, temperature=0.8, seed=seed_text)\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "67e75fbc-e4a4-42af-af78-e0960a327cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [stoi['<S>']] * block_size\n",
    "s = 'a centaur was standing over him, not ronan or bane; '\n",
    "\n",
    "l = len(s)\n",
    "for i, c in enumerate(s):\n",
    "    context[block_size - l + i] = stoi[c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b0d0ea28-840f-47b2-9676-a61112dca8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S><S>a centaur was standing over him, not ronan or bane; '"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([itos[c] for c in context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39518b-a74e-4284-a3ba-236de1f86e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
