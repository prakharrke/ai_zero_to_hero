{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0bc3af-1e1e-429d-aa89-8bebdbb66a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c32315-247c-41f8-b887-ac4f6e924a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      if x.ndim == 2:\n",
    "        dim = 0\n",
    "      elif x.ndim == 3:\n",
    "        dim = (0,1)\n",
    "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "      xvar = x.var(dim, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Embedding:\n",
    "  \n",
    "  def __init__(self, num_embeddings, embedding_dim):\n",
    "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "    \n",
    "  def __call__(self, IX):\n",
    "    self.out = self.weight[IX].transpose(1, 2)\n",
    "    \n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class FlattenConsecutive:\n",
    "  \n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    B, T, C = x.shape\n",
    "    x = x.view(B, T//self.n, C*self.n)\n",
    "    if x.shape[1] == 1:\n",
    "      x = x.squeeze(1)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        self.out = x.view(x.shape[0], -1)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Sequential:\n",
    "  \n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    # get parameters of all layers and stretch them out into one list\n",
    "    return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "# --------------------------------------------\n",
    "class Conv1d:\n",
    "    def __init__(self, sequence_length, in_channels, out_channels, kernel=2, stride=1, dilation=1):\n",
    "        self. sequence_length = sequence_length\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.filters = torch.randn((out_channels, in_channels, kernel)) * 0.1\n",
    "        self.bias = torch.randn(out_channels) * 0\n",
    "    def __call__(self, x):\n",
    "        # Compute effective kernel size based on dilation \n",
    "        effective_kernel = ((kernel - 1) * self.dilation) + 1\n",
    "        N, C, L = x.shape\n",
    "        # create the sliding windows of the input \n",
    "        x_unfolded = x.unfold(2, self.effective_kernel, self.stride)\n",
    "        \n",
    "        # Extract dilated inputs from x_unfolded which used effective_kernel\n",
    "        x_unfolded = x_unfolded[:, :, ]\n",
    "        Lout = ((self.sequence_length - self.kernel) // self.stride) + 1\n",
    "\n",
    "        # Before cross correlation, we need to broadcast the filters and the input correctly\n",
    "        x_unfolded = x_unfolded.view(N, 1, C, Lout, self.kernel)\n",
    "        filters = self.filters.view(1, self.out_channels, self.in_channels, 1, self.kernel)\n",
    "\n",
    "        # Perform element wise multiplication\n",
    "        self.out = torch.mul(x_unfolded, filters).sum((2, 4)) + self.bias.view(1, self.out_channels, 1)\n",
    "        return self.out        \n",
    "    \n",
    "    def parameters(self): \n",
    "        return [self.filters]\n",
    "\n",
    "class ReLu: \n",
    "    def __call__(self, x):\n",
    "        self.out = torch.relu(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "        \n",
    "class Transpose:\n",
    "    def __call__(self, x):\n",
    "        self.out = x.transpose(1, 2)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67a3befc-00e9-46b8-b981-fbbc48504bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((1, 10, 4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65c8f2cf-cdcb-46b3-b158-d739c0111231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 3, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unfold(2, 2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e54a830a-78cb-48d4-9334-2c636fee284a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, torch.Size([1, 8, 2]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = 2\n",
    "sequence_length = 10\n",
    "torch.arange(10).view(1, 10).unfold(1, kernel, 1).shape\n",
    "# L = (10 - 2) +  1 = 9 sequence_length or LOut without dilation\n",
    "dilation = 2 \n",
    "# effective kernel size \n",
    "effective_kernel = (kernel - 1) * dilation +  1\n",
    "x = torch.arange(10).view(1, 10).unfold(1, effective_kernel, 1)[:, :, ::dilation]\n",
    "Lout = (sequence_length - effective_kernel) +  1\n",
    "Lout, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c6881d04-1a6a-4405-b493-a40bb3e820be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 2])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters = torch.randn((1, Lout, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0810b07c-b683-47e6-957b-4134f3f8e82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 6, 2])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((32, 10, 8))\n",
    "x.unfold(2, 3, 1)[:, :, :, ::2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "36d3cd02-abfe-48d0-b743-0015325cc1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 6]), torch.Size([32, 10, 8]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.randn((32, 10, 8)) # Follows [N, C, L]\n",
    "x = x1\n",
    "# Mock conv1  \n",
    "filters = torch.randn((1, 10, 2))\n",
    "\n",
    "#unfold the input so it can be cross correlated with the filters \n",
    "x = x.unfold(2, 2, 1)\n",
    "filters = filters.view(1, 10, 1, 2)\n",
    "x = x.view(32, 10, 7, 2)\n",
    "out = torch.mul(x, filters).sum((1, 3)) # Output of first conv1d layer is [32, 1, 7]\n",
    "\n",
    "out = out.view(32, 1, 7)\n",
    "out = torch.relu(out)\n",
    "\n",
    "# Mock conv2\n",
    "filters = torch.randn((1, 1, 2))\n",
    "out = out.unfold(2, 2, 1)\n",
    "filters = filters.view(1, 1, 1, 2)\n",
    "out = out.view(32, 1, 6, 2)\n",
    "out = torch.mul(out, filters)\n",
    "out = out.sum((1, 3))\n",
    "out = torch.relu(out.view(32, 1, 6))\n",
    "\n",
    "out.shape, x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "12fba7dc-bc6f-4d81-9282-35bed0a85887",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "only one dimension can be inferred",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only one dimension can be inferred"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2f091056-13c4-4d08-9b4a-806e9898e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = torch.randn((1, 1, 1))\n",
    "new_x = torch.mul(x1, ws).sum(1).view(32, 1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "66d23f5c-991d-4889-8d3f-c0634ad29db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 8])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "out_padded = F.pad(out, (1, 1))\n",
    "out_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bcf9323e-7895-4b7c-bf7f-d596f71ea488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9552e-01,  1.0429e-02, -7.9978e-01, -3.6721e-01,  7.5553e-01,\n",
       "           8.9859e-02,  4.6809e-01,  6.7790e-04]],\n",
       "\n",
       "        [[ 3.5495e-01, -4.0436e-01, -2.3255e-01, -5.2633e-01, -2.0903e-01,\n",
       "          -4.6143e-02,  1.3084e-01,  2.2296e-01]],\n",
       "\n",
       "        [[-6.0859e-01,  1.2943e-01,  3.1384e-01,  7.3723e-01,  1.8838e-01,\n",
       "           6.2714e-01, -1.2009e+00,  2.4364e-01]],\n",
       "\n",
       "        [[ 1.3663e-01,  1.2647e+00,  5.1808e-01,  1.4569e-02, -9.5868e-01,\n",
       "           4.9978e-01,  2.2269e-01,  1.3858e+00]],\n",
       "\n",
       "        [[ 7.2894e-02,  1.8587e-01, -2.0079e-01, -7.4890e-01,  2.7596e-02,\n",
       "           6.5100e-01, -5.4487e-01, -2.3686e-01]],\n",
       "\n",
       "        [[ 6.0973e-01, -3.3955e-01,  5.6073e-01,  6.4402e-01,  4.9537e-01,\n",
       "           6.1137e-01, -4.5211e-01, -5.8515e-01]],\n",
       "\n",
       "        [[ 1.1916e+00,  7.2823e-02,  7.0781e-01,  1.1280e+00, -6.6807e-01,\n",
       "          -1.0612e-01, -7.7295e-01,  1.0129e+00]],\n",
       "\n",
       "        [[ 7.4925e-02, -4.9892e-01, -1.1025e-02, -1.1195e-01,  8.3276e-01,\n",
       "           4.5315e-01, -1.0737e-01, -7.9665e-01]],\n",
       "\n",
       "        [[-1.8804e-01, -1.9809e-02,  9.9422e-02,  2.2406e-01, -2.9929e-01,\n",
       "          -1.7779e-01,  1.4623e-01, -2.4562e-01]],\n",
       "\n",
       "        [[ 7.6244e-01, -1.0378e-03, -4.7980e-02,  7.4318e-02, -1.6725e-01,\n",
       "           5.2409e-01,  3.0058e-01,  1.5740e-01]],\n",
       "\n",
       "        [[ 2.2068e-01,  6.4753e-02, -4.4179e-01, -5.0827e-03,  6.8251e-02,\n",
       "          -9.1096e-01,  2.3405e-01,  9.8094e-01]],\n",
       "\n",
       "        [[-2.3997e-01,  9.4587e-01, -3.0456e-01,  1.1019e+00,  1.5663e-01,\n",
       "           3.1141e-01,  3.2388e-01,  3.3880e-01]],\n",
       "\n",
       "        [[ 4.9231e-01,  2.8987e-01,  8.3214e-01, -3.2202e-01, -2.7661e-01,\n",
       "           2.0423e-01, -3.0845e-01, -3.8077e-01]],\n",
       "\n",
       "        [[-4.2598e-02,  8.8901e-01, -1.2997e+00,  4.7391e-01, -8.7644e-02,\n",
       "          -3.0095e-01,  5.4070e-01, -9.1065e-01]],\n",
       "\n",
       "        [[ 2.8155e-02, -6.6191e-01,  6.9243e-01,  1.7734e-01, -1.6067e-01,\n",
       "           1.1982e-01,  5.6589e-01, -2.9524e-01]],\n",
       "\n",
       "        [[ 5.6273e-01, -4.4569e-01, -1.2121e+00,  2.8387e-01, -4.6037e-01,\n",
       "          -2.0548e-01, -5.4512e-01,  1.2527e-01]],\n",
       "\n",
       "        [[-1.3486e-01,  4.3388e-01,  2.1490e-01,  4.7029e-01,  6.7948e-01,\n",
       "          -2.1744e-01,  2.3812e-01,  1.0605e+00]],\n",
       "\n",
       "        [[ 6.8576e-01, -6.5530e-01, -4.3420e-01, -2.6103e-01,  1.0238e-01,\n",
       "           2.4027e-01, -6.5595e-01,  2.9377e-01]],\n",
       "\n",
       "        [[-1.2846e-01,  1.7742e-01,  5.4340e-01, -7.6676e-01, -1.6765e-01,\n",
       "          -1.5500e-01, -5.4765e-01,  1.5240e-01]],\n",
       "\n",
       "        [[-1.0278e+00, -3.1721e-01,  7.6963e-02,  5.4180e-01, -1.3712e-01,\n",
       "          -9.4177e-01, -2.3397e-01,  3.3086e-01]],\n",
       "\n",
       "        [[-6.2163e-01, -9.5903e-02, -9.2065e-01, -2.5870e-01, -4.7932e-01,\n",
       "          -6.4867e-01,  3.1915e-01,  2.3293e-01]],\n",
       "\n",
       "        [[-6.1568e-01,  1.6469e-02, -2.6798e-02,  8.2308e-02,  1.4351e-02,\n",
       "           3.1702e-01, -6.2715e-01,  4.0182e-01]],\n",
       "\n",
       "        [[ 1.4102e+00, -5.2668e-01, -4.6616e-02,  9.5228e-01, -7.5912e-02,\n",
       "          -9.9753e-01,  1.6171e-01,  1.3289e+00]],\n",
       "\n",
       "        [[ 1.6451e-01, -8.0462e-01,  4.4423e-01, -2.5837e-01, -1.4206e-01,\n",
       "          -2.2938e-01,  7.5601e-01,  6.5847e-01]],\n",
       "\n",
       "        [[ 1.0803e+00,  2.7725e-01, -2.9294e-01, -4.6273e-01, -9.2807e-01,\n",
       "           6.3888e-02, -3.6537e-01,  8.8453e-01]],\n",
       "\n",
       "        [[ 2.2821e-01, -1.6775e-01, -2.9850e-01, -4.2781e-01,  3.9284e-01,\n",
       "          -2.3724e-02, -4.9129e-01, -5.1233e-01]],\n",
       "\n",
       "        [[-3.0749e-01, -1.5252e-01,  3.7673e-01,  1.5430e-01,  8.1045e-01,\n",
       "          -4.7259e-01,  1.8281e-02,  1.6466e-01]],\n",
       "\n",
       "        [[ 1.6269e-01,  2.6469e-01, -5.7193e-01,  3.4993e-01,  2.0837e-01,\n",
       "           8.0498e-01,  4.0531e-01,  7.3171e-01]],\n",
       "\n",
       "        [[ 5.8168e-01,  9.6046e-02,  2.5933e-01, -4.0834e-01, -5.7533e-02,\n",
       "          -4.6101e-01, -8.5990e-01,  4.2445e-02]],\n",
       "\n",
       "        [[ 1.6251e-01, -1.7321e-01, -2.3059e-01,  6.7990e-01,  3.4322e-01,\n",
       "          -7.7856e-01, -3.4746e-01,  1.8009e-01]],\n",
       "\n",
       "        [[-5.5131e-01, -4.1540e-01,  8.2612e-01,  3.3728e-01, -1.2089e-01,\n",
       "           3.2633e-02,  1.6209e-01, -2.5294e-01]],\n",
       "\n",
       "        [[ 1.2967e+00,  1.2866e-01,  2.5014e-01, -5.6932e-01,  6.1000e-01,\n",
       "           9.6557e-01, -6.9826e-01, -4.2203e-01]]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_padded + new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2da42a-d5da-4ef2-b1ba-aaf788f6bbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
